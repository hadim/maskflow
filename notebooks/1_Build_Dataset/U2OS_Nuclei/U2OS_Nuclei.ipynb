{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclei of U2OS cells in a chemical screen\n",
    "\n",
    "- Dataset [BBBC039](https://data.broadinstitute.org/bbbc/BBBC039/) available from the [Broad Bioimage Benchmark Collection](https://data.broadinstitute.org/bbbc/index.html) ([Ljosa et al., Nature Methods, 2012](http://dx.doi.org/10.1038/nmeth.2083))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "from skimage import morphology\n",
    "\n",
    "import sys; sys.path.append(\"../../../\")\n",
    "import maskflow\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/U2OS_Nuclei\")\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = maskflow.config.load_config(\"config.yaml\")\n",
    "\n",
    "# Copy config next to data folder\n",
    "maskflow.config.save_config(config, root_dir / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_url = \"https://data.broadinstitute.org/bbbc/BBBC039/images.zip\"\n",
    "masks_url = \"https://data.broadinstitute.org/bbbc/BBBC039/masks.zip\"\n",
    "\n",
    "# Download and exctract dataset in user data dir\n",
    "images_path = maskflow.archive.open_archive(images_url, appname=\"maskflow\", progressbar=True, erase=False)\n",
    "images_path = images_path / 'images'\n",
    "masks_path = maskflow.archive.open_archive(masks_url, appname=\"maskflow\", progressbar=True, erase=False)\n",
    "masks_path = masks_path / 'masks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbdbc1c9be74edd9f82ea420364a097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discard /home/hadim/.local/share/maskflow/images/images/IXMtest_F13_s7_w13C1B1D8C-293E-454F-B0FD-6C2C3F9F5173.tif\n",
      "Discard /home/hadim/.local/share/maskflow/images/images/IXMtest_L01_s2_w1E5038251-DBA3-44D0-BC37-E43E2FC8C174.tif\n",
      "Discard /home/hadim/.local/share/maskflow/images/images/IXMtest_L10_s6_w12D12D64C-2639-4CA8-9BB4-99F92C9B7068.tif\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_size = 0.8  # From 0 to 1\n",
    "png_compression_level = 0  # From 0 to 9\n",
    "\n",
    "images_paths = list(images_path.iterdir())\n",
    "len_dataset = len(images_paths)\n",
    "\n",
    "train_ids, _ = train_test_split(np.arange(0, len_dataset), train_size=training_size)\n",
    "\n",
    "train_dir = data_dir / \"train_dataset\"\n",
    "train_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "test_dir = data_dir / \"test_dataset\"\n",
    "test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_annotations_path = data_dir / \"train_annotations.json\"\n",
    "test_annotations_path = data_dir / \"test_annotations.json\"\n",
    "\n",
    "train_annotations = maskflow.dataset.get_base_annotations(config['CLASS_NAMES'], supercategory=\"nuclei\")\n",
    "test_annotations = maskflow.dataset.get_base_annotations(config['CLASS_NAMES'], supercategory=\"nuclei\")\n",
    "\n",
    "for image_id, fname in tqdm.tqdm_notebook(enumerate(images_paths), total=len(images_paths)):\n",
    "     \n",
    "    image = np.array(Image.open(fname))    \n",
    "    image = exposure.rescale_intensity(image, out_range='uint8')\n",
    "    image = image.astype(\"uint8\")\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    image = np.tile(image, [1, 1, 3])\n",
    "    \n",
    "    masks = np.array(Image.open(masks_path / fname.with_suffix('.png').name))\n",
    "    masks = masks[:, :, 0]\n",
    "    masks = morphology.label(masks)\n",
    "\n",
    "    masks_list = []\n",
    "    for pixel in np.unique(masks)[1:]:\n",
    "        masks_list.append(masks == pixel)\n",
    "    masks = np.array(masks_list)\n",
    "    \n",
    "    if masks.shape[0] == 0:\n",
    "        print(f\"Discard {fname}\")\n",
    "        continue\n",
    "    \n",
    "    # Manual crop to make the dataset smaller\n",
    "    image = image[50:450, 150:550]\n",
    "    masks = masks[:, 50:450, 150:550]\n",
    "    \n",
    "    # We check masks are not empty\n",
    "    to_keep = np.where(masks.sum(-1).sum(-1) > 0)[0]\n",
    "    masks = masks[to_keep]\n",
    "    \n",
    "    if masks.shape[0] == 0:\n",
    "        print(f\"Discard {fname}\")\n",
    "        continue\n",
    "        \n",
    "    class_ids = np.ones(masks.shape[0]).astype('uint32')\n",
    "    \n",
    "    basename = f\"nucleus_{image_id:04d}.png\"\n",
    "    \n",
    "    # Get the annotation in the COCO format.\n",
    "    image_info, image_annotations = maskflow.dataset.get_annotations(image_id, basename, image, masks, class_ids)\n",
    "    \n",
    "    if image_id in train_ids:\n",
    "        image_path = train_dir / basename\n",
    "        train_annotations[\"images\"].append(image_info)\n",
    "        train_annotations[\"annotations\"].extend(image_annotations)\n",
    "    else:\n",
    "        image_path = test_dir / basename\n",
    "        test_annotations[\"images\"].append(image_info)\n",
    "        test_annotations[\"annotations\"].extend(image_annotations)\n",
    "    \n",
    "    Image.fromarray(image).save(str(image_path), compress_level=png_compression_level)\n",
    "    \n",
    "maskflow.dataset.save_annotations(train_annotations, train_annotations_path)\n",
    "maskflow.dataset.save_annotations(test_annotations, test_annotations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup Raw Data\n",
    "import shutil\n",
    "shutil.rmtree(images_path.parent)\n",
    "shutil.rmtree(masks_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-09 12:03:44,023:WARNING:maskrcnn_benchmark.data.build: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n"
     ]
    }
   ],
   "source": [
    "config['SOLVER']['IMS_PER_BATCH'] = 3\n",
    "config['TEST']['IMS_PER_BATCH'] = 3\n",
    "\n",
    "# Number of batch to load\n",
    "n = 1\n",
    "\n",
    "# Load some data\n",
    "data_loader = maskflow.dataset.get_data_loader(config, data_dir, is_train=True)\n",
    "some_data = [iter(data_loader).next() for _ in range(n)]\n",
    "\n",
    "# Retrieve category's names\n",
    "categories = data_loader.dataset.coco.cats\n",
    "\n",
    "for batch_image, batch_target, batch_idx in some_data:\n",
    "    maskflow.viz.batch_display_top_masks(batch_image, batch_target, batch_idx, categories,\n",
    "                                         basesize=12, limit=2, cmap=\"PuBu_r\",\n",
    "                                         pixel_mean=config['INPUT']['PIXEL_MEAN'],\n",
    "                                         pixel_std=config['INPUT']['PIXEL_STD'])"
   ]
  }
 ],
 "metadata": {
  "gist_info": {
   "gist_id": null,
   "gist_url": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
