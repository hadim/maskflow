{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import joblib\n",
    "import cv2\n",
    "import tqdm\n",
    "import read_roi\n",
    "\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "import maskflow\n",
    "from maskflow import simuscope\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/Microtubule\")\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "image_dir = data_dir / \"Image\"\n",
    "image_dir.mkdir(parents=True, exist_ok=True)\n",
    "mask_dir = data_dir / \"Mask\"\n",
    "mask_dir.mkdir(parents=True, exist_ok=True)\n",
    "class_dir = data_dir / \"Class\"\n",
    "class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "params = maskflow.load_parameters(\"parameters.yml\")\n",
    "class_names = params[\"CLASS_NAMES\"]\n",
    "\n",
    "# Copy config next to data folder\n",
    "maskflow.save_parameters(params, root_dir / \"parameters.yml\")\n",
    "\n",
    "# When drawing microtubule on the mask\n",
    "line_thickness = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "\n",
    "def get_line(x):\n",
    "    d = {}\n",
    "    d[\"start_x\"] = x[x.type == \"seed\"][\"start_x\"].values[0]\n",
    "    d[\"start_y\"] = x[x.type == \"seed\"][\"start_y\"].values[0]\n",
    "    d[\"end_x\"] = x[x.type == \"seed\"][\"end_x\"].values[0]\n",
    "    d[\"end_y\"] = x[x.type == \"seed\"][\"end_y\"].values[0]\n",
    "    return pd.DataFrame([d])\n",
    "\n",
    "\n",
    "def draw_line(image, line, line_thickness):\n",
    "    line = np.round(line).astype(\"int16\")\n",
    "    p1 = (line[\"start_x\"], line[\"start_y\"])\n",
    "    p2 = (line[\"end_x\"], line[\"end_y\"])\n",
    "    _, p1, p2 = cv2.clipLine((0, 0, image.shape[0], image.shape[1]), p1, p2)\n",
    "    image = cv2.line(image, p1, p2, (1,), line_thickness)\n",
    "    return image\n",
    "\n",
    "\n",
    "def convert_rois_to_json(rois):\n",
    "    json_roi = {\"microtubule\": {}}\n",
    "    mt = json_roi[\"microtubule\"]\n",
    "    mt[\"end_x\"] = {}\n",
    "    mt[\"end_y\"] = {}\n",
    "    mt[\"frame\"] = {}\n",
    "    mt[\"mt_id\"] = {}\n",
    "    mt[\"start_x\"] = {}\n",
    "    mt[\"start_y\"] = {}\n",
    "    mt[\"type\"] = {}\n",
    "\n",
    "    for i, (roi_name, roi) in enumerate(rois.items()):\n",
    "        mt[\"type\"][str(i)] = \"seed\"\n",
    "        mt[\"frame\"][str(i)] = 0\n",
    "        mt[\"mt_id\"][str(i)] = i\n",
    "        \n",
    "        if \"x1\" in roi.keys():\n",
    "            mt[\"end_x\"][str(i)] = roi[\"x2\"]\n",
    "            mt[\"end_y\"][str(i)] = roi[\"y2\"]\n",
    "            mt[\"start_y\"][str(i)] = roi[\"y1\"]\n",
    "            mt[\"start_x\"][str(i)] = roi[\"x1\"]\n",
    "        else:\n",
    "            mt[\"end_x\"][str(i)] = roi[\"x\"][-1]\n",
    "            mt[\"end_y\"][str(i)] = roi[\"y\"][-1]\n",
    "            mt[\"start_y\"][str(i)] = roi[\"y\"][0]\n",
    "            mt[\"start_x\"][str(i)] = roi[\"x\"][0]\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset consists of a root folder containing 3 sub-folders:\n",
    "\n",
    "- `Image/`: it contains the original images stored as TIF files. Shape is [H, W, C].\n",
    "- `Mask/`: it contains the masks stored as TIF files. Shape is [H, W, N].\n",
    "- `Class/`: Class ids as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Artificial Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 1, 512, 512)\n",
      "Image memory size: 2.00 MB\n",
      "Channels: ['channel_1']\n",
      "Objects: [<maskflow.simuscope.builder.object_builder.microtubule_builder.SimpleMicrotubuleBuilder object at 0x7f4d0bddc710>]\n",
      "\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "model_name = \"simple_microtubule\"\n",
    "model = simuscope.Model.load_model(model_name)\n",
    "\n",
    "model.acquisition.n_frames = 1\n",
    "model.acquisition.channels.pop(\"channel_2\")\n",
    "\n",
    "builder = model.get_builder()\n",
    "print(builder)\n",
    "\n",
    "# Setup image generation parameter\n",
    "snr_range = np.arange(1.3, 4, 0.6)\n",
    "n_mts_range = np.linspace(10, 200, 4)\n",
    "n = 50\n",
    "\n",
    "image_size = 1280\n",
    "length_loc = 6\n",
    "length_scale = 5\n",
    "\n",
    "total_images = snr_range.shape[0] * n_mts_range.shape[0] * n\n",
    "print(total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  10 out of  20 | elapsed: 12.4min remaining: 12.4min\n",
      "[Parallel(n_jobs=16)]: Done  20 out of  20 | elapsed: 30.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset\n",
    "\n",
    "def create(*args):\n",
    "    snr, n_mts = args[0]\n",
    "    \n",
    "    model.acquisition.channels[\"channel_1\"].snr = snr\n",
    "    mt_obj = model.objects[\"microtubule\"]\n",
    "    mt_obj.parameters[\"nucleation_rate\"][\"parameters\"][\"loc\"] = 0\n",
    "    mt_obj.parameters[\"n_microtubules\"][\"parameters\"][\"loc\"] = n_mts\n",
    "    mt_obj.parameters[\"initial_length\"][\"parameters\"][\"loc\"] = length_loc\n",
    "    mt_obj.parameters[\"initial_length\"][\"parameters\"][\"scale\"] = length_scale\n",
    "\n",
    "    for i in range(n):\n",
    "        basename = f\"image_snr_{snr:.1f}_n-mts_{n_mts}_id_{i}\"\n",
    "\n",
    "        model.microscope.camera.chip_size_height = image_size\n",
    "        model.microscope.camera.chip_size_width = image_size\n",
    "        \n",
    "        builder = model.get_builder()\n",
    "        images = builder.build(keep_images=False)\n",
    "        \n",
    "        # Rescale intensities\n",
    "        builder.image = rescale_intensity(builder.image, out_range=np.uint8)\n",
    "        \n",
    "        # Save image\n",
    "        builder.save_image(str(image_dir / (basename + \".tif\")))\n",
    "        \n",
    "        objects = builder.get_objects_as_dict()\n",
    "        n_objects = len(objects[\"microtubule\"][\"mt_id\"])\n",
    "\n",
    "        # All object are of class \"1\" for a microtubule\n",
    "        class_ids = np.repeat(1, n_objects)\n",
    "\n",
    "        # Save class ids\n",
    "        class_ids_path = class_dir / (basename + \".csv\")\n",
    "        pd.Series(class_ids).to_csv(class_ids_path, index=False)\n",
    "        \n",
    "        data = pd.DataFrame.from_dict(objects[\"microtubule\"])\n",
    "\n",
    "        width = model.microscope.camera.chip_size_width\n",
    "        height = model.microscope.camera.chip_size_height\n",
    "\n",
    "        lines = data.groupby(\"mt_id\").apply(get_line).reset_index(drop=True)\n",
    "        count = lines.shape[0]\n",
    "\n",
    "        mask = np.zeros((width, height, count), dtype=np.uint8)\n",
    "        for i, line in lines.iterrows():\n",
    "            mask[:, :, i] = draw_line(mask[:, :, i].copy(), line, line_thickness)\n",
    "\n",
    "        # Handle occlusions\n",
    "        handle_occlusion = True\n",
    "        if handle_occlusion:\n",
    "            occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "            for i in range(count - 2, -1, -1):\n",
    "                mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "                occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "\n",
    "        # Save mask as tiff file\n",
    "        mask_path = mask_dir / (basename + \".tif\")\n",
    "        tifffile.imsave(str(mask_path), mask)\n",
    "    \n",
    "parameters = list(itertools.product(snr_range, n_mts_range))\n",
    "p = joblib.Parallel(n_jobs=16, verbose=1)\n",
    "_ = p(map(joblib.delayed(create), parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment and Copy the Annotated Dataset\n",
    "\n",
    "Here we copy a manually annotated dataset to the final training dataset. We also use augmentation on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [05:26<00:00, 12.57s/it]\n"
     ]
    }
   ],
   "source": [
    "manual_data_dir = root_dir / \"Manual Training Dataset\"\n",
    "processed_data_dir = root_dir / \"Manual Training Dataset/Processed\"\n",
    "\n",
    "n_augmentation_per_image = 10\n",
    "\n",
    "fnames = [fname.with_suffix(\".tif\") for fname in processed_data_dir.glob(\"*.zip\")]\n",
    "#fnames = fnames[:2]\n",
    "\n",
    "# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "# e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "seq = iaa.Sequential([iaa.Fliplr(p=0.5), # horizontally flip 50% of all images\n",
    "                      iaa.Flipud(p=0.5), # vertically flip 20% of all images\n",
    "                       sometimes(iaa.Affine(\n",
    "                           scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},  # scale images to 80-120% of their size, individually per axis\n",
    "                           translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},  # translate by -2 to +2 percent (per axis)\n",
    "                           rotate=(-45, 45),  # rotate by -15 to +15 degrees\n",
    "                           shear=(-5, 5),  # shear by -5 to +5 degrees\n",
    "                           order=[0, 1],  # use nearest neighbour or bilinear interpolation (fast)\n",
    "                           mode=\"constant\"))])\n",
    "\n",
    "for fname in tqdm.tqdm(fnames, total=len(fnames)):\n",
    "    \n",
    "    basename = fname.stem\n",
    "    \n",
    "    # Copy image file\n",
    "    new_image_path = image_dir / (basename + \".tif\")\n",
    "    im = tifffile.imread(str(fname))\n",
    "    \n",
    "    im = rescale_intensity(im, out_range=np.uint8)\n",
    "    tifffile.imsave(str(new_image_path), im)\n",
    "    \n",
    "    # Convert ZIP rois to JSON rois\n",
    "    rois = read_roi.read_roi_zip(fname.with_suffix(\".zip\"))\n",
    "    objects = convert_rois_to_json(rois)\n",
    "    \n",
    "    width = im.shape[1]\n",
    "    height = im.shape[0]\n",
    "\n",
    "    data = pd.DataFrame.from_dict(objects)\n",
    "    \n",
    "    lines = data.groupby(\"mt_id\").apply(get_line).reset_index(drop=True)\n",
    "    count = lines.shape[0]\n",
    "\n",
    "    mask = np.zeros((height, width, count), dtype=np.uint8)\n",
    "    for i, line in lines.iterrows():\n",
    "        mask[:, :, i] = draw_line(mask[:, :, i].copy(), line, line_thickness)\n",
    "\n",
    "    # Handle occlusions\n",
    "    handle_occlusion = True\n",
    "    if handle_occlusion:\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count - 2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "\n",
    "    # All object are of class \"1\" for a microtubule\n",
    "    class_ids = np.repeat(1, mask.shape[-1])\n",
    "            \n",
    "    # Save mask as tiff file\n",
    "    mask_path = mask_dir / (basename + \".tif\")\n",
    "    tifffile.imsave(str(mask_path), mask)\n",
    "    \n",
    "    # Save class ids \n",
    "    class_ids_path = class_dir / (basename + \".csv\")\n",
    "    pd.Series(class_ids).to_csv(class_ids_path, index=False)\n",
    "    \n",
    "   # Augmentation: we create new images from the above one.\n",
    "    for i in range(n_augmentation_per_image):\n",
    "        new_image_path = image_dir / (basename + f\"_AUGMENTED_{i}.tif\")\n",
    "        new_mask_path = mask_dir / (basename + f\"_AUGMENTED_{i}.tif\")\n",
    "        new_class_ids_path = class_dir / (basename + f\"_AUGMENTED_{i}.csv\")\n",
    "\n",
    "        seq_det = seq.to_deterministic()\n",
    "\n",
    "        new_im = seq_det.augment_image(im)\n",
    "        new_mask = seq_det.augment_image(mask)\n",
    "        \n",
    "        # Note that some boxes might be all zeros if the corresponding mask got cropped out.\n",
    "        # and here is to filter them out\n",
    "        _idx = np.sum(new_mask, axis=(0, 1)) > 0\n",
    "        new_mask = new_mask[:, :, _idx]\n",
    "        new_class_ids = class_ids[_idx]\n",
    "\n",
    "        tifffile.imsave(str(new_image_path), new_im)\n",
    "        tifffile.imsave(str(new_mask_path), new_mask)\n",
    "        pd.Series(new_class_ids).to_csv(new_class_ids_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
