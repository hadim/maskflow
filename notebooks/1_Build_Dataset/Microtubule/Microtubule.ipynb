{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import joblib\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "import read_roi\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "import maskflow\n",
    "from maskflow import simuscope\n",
    "\n",
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/Microtubule\")\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "image_dir = data_dir / \"Image\"\n",
    "image_dir.mkdir(parents=True, exist_ok=True)\n",
    "mask_dir = data_dir / \"Mask\"\n",
    "mask_dir.mkdir(parents=True, exist_ok=True)\n",
    "class_dir = data_dir / \"Class\"\n",
    "class_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = maskflow.load_config(\"config.yml\")\n",
    "class_names = config[\"CLASS_NAMES\"]\n",
    "\n",
    "# Copy config next to data folder\n",
    "maskflow.save_config(config, root_dir / \"config.yml\")\n",
    "\n",
    "# When drawing microtubule on the mask\n",
    "line_thickness = 4\n",
    "\n",
    "n_augm = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "The dataset consists of a root folder containing 3 sub-folders:\n",
    "\n",
    "- `Image/`: it contains the original images stored as TIF files. Shape is [H, W, C].\n",
    "- `Mask/`: it contains the masks stored as TIF files. Shape is [H, W, N].\n",
    "- `Class/`: Class ids as csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Fake Microtubule Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (1, 1, 512, 512)\n",
      "Image memory size: 2.00 MB\n",
      "Channels: ['channel_1']\n",
      "Objects: [<maskflow.simuscope.builder.object_builder.microtubule_builder.SimpleMicrotubuleBuilder object at 0x7f72501fb550>]\n",
      "\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "model_name = \"simple_microtubule\"\n",
    "model = simuscope.Model.load_model(model_name)\n",
    "\n",
    "model.acquisition.n_frames = 1\n",
    "model.acquisition.channels.pop(\"channel_2\")\n",
    "\n",
    "builder = model.get_builder()\n",
    "print(builder)\n",
    "\n",
    "# Setup image generation parameter\n",
    "snr_range = np.arange(1.3, 4, 0.6)\n",
    "n_mts_range = np.arange(10, 200, 50)\n",
    "n = 50\n",
    "\n",
    "size_range = (512, 1280)\n",
    "length_loc = 6\n",
    "length_scale = 5\n",
    "\n",
    "total_images = snr_range.shape[0] * n_mts_range.shape[0] * n\n",
    "print(total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "\n",
    "def get_line(x):\n",
    "    d = {}\n",
    "    d[\"start_x\"] = x[x.type == \"seed\"][\"start_x\"].values[0]\n",
    "    d[\"start_y\"] = x[x.type == \"seed\"][\"start_y\"].values[0]\n",
    "    d[\"end_x\"] = x[x.type == \"seed\"][\"end_x\"].values[0]\n",
    "    d[\"end_y\"] = x[x.type == \"seed\"][\"end_y\"].values[0]\n",
    "    return pd.DataFrame([d])\n",
    "\n",
    "\n",
    "def draw_line(image, line, line_thickness):\n",
    "    line = np.round(line).astype(\"int16\")\n",
    "    p1 = (line[\"start_x\"], line[\"start_y\"])\n",
    "    p2 = (line[\"end_x\"], line[\"end_y\"])\n",
    "    _, p1, p2 = cv2.clipLine((0, 0, image.shape[0], image.shape[1]), p1, p2)\n",
    "    image = cv2.line(image, p1, p2, (1,), line_thickness)\n",
    "    return image\n",
    "\n",
    "\n",
    "def convert_rois_to_json(rois):\n",
    "    json_roi = {\"microtubule\": {}}\n",
    "    mt = json_roi[\"microtubule\"]\n",
    "    mt[\"end_x\"] = {}\n",
    "    mt[\"end_y\"] = {}\n",
    "    mt[\"frame\"] = {}\n",
    "    mt[\"mt_id\"] = {}\n",
    "    mt[\"start_x\"] = {}\n",
    "    mt[\"start_y\"] = {}\n",
    "    mt[\"type\"] = {}\n",
    "\n",
    "    for i, (roi_name, roi) in enumerate(rois.items()):\n",
    "        mt[\"type\"][str(i)] = \"seed\"\n",
    "        mt[\"frame\"][str(i)] = 0\n",
    "        mt[\"mt_id\"][str(i)] = i\n",
    "        \n",
    "        if \"x1\" in roi.keys():\n",
    "            mt[\"end_x\"][str(i)] = roi[\"x2\"]\n",
    "            mt[\"end_y\"][str(i)] = roi[\"y2\"]\n",
    "            mt[\"start_y\"][str(i)] = roi[\"y1\"]\n",
    "            mt[\"start_x\"][str(i)] = roi[\"x1\"]\n",
    "        else:\n",
    "            mt[\"end_x\"][str(i)] = roi[\"x\"][-1]\n",
    "            mt[\"end_y\"][str(i)] = roi[\"y\"][-1]\n",
    "            mt[\"start_y\"][str(i)] = roi[\"y\"][0]\n",
    "            mt[\"start_x\"][str(i)] = roi[\"x\"][0]\n",
    "    return mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed: 22.5min finished\n"
     ]
    }
   ],
   "source": [
    "# Generate the dataset\n",
    "\n",
    "def create(*args):\n",
    "    snr, n_mts = args[0]\n",
    "    \n",
    "    model.acquisition.channels[\"channel_1\"].snr = snr\n",
    "    mt_obj = model.objects[\"microtubule\"]\n",
    "    mt_obj.parameters[\"nucleation_rate\"][\"parameters\"][\"loc\"] = 0\n",
    "    mt_obj.parameters[\"n_microtubules\"][\"parameters\"][\"loc\"] = n_mts\n",
    "    mt_obj.parameters[\"initial_length\"][\"parameters\"][\"loc\"] = length_loc\n",
    "    mt_obj.parameters[\"initial_length\"][\"parameters\"][\"scale\"] = length_scale\n",
    "\n",
    "    for i in range(n):\n",
    "        basename = f\"image_snr_{snr:.1f}_n-mts_{n_mts}_id_{i}\"\n",
    "\n",
    "        random_size = np.random.randint(*size_range)\n",
    "        model.microscope.camera.chip_size_height = random_size\n",
    "        model.microscope.camera.chip_size_width = random_size\n",
    "        \n",
    "        builder = model.get_builder()\n",
    "        images = builder.build(keep_images=False)\n",
    "        \n",
    "        # Save image\n",
    "        builder.save_image(str(image_dir / (basename + \".tif\")))\n",
    "        \n",
    "        objects = builder.get_objects_as_dict()\n",
    "        n_objects = len(objects[\"microtubule\"][\"mt_id\"])\n",
    "\n",
    "        # All object are of class \"1\" for a microtubule\n",
    "        class_ids = np.repeat(1, n_objects)\n",
    "\n",
    "        # Save class ids\n",
    "        class_ids_path = class_dir / (basename + \".csv\")\n",
    "        pd.Series(class_ids).to_csv(class_ids_path, index=False)\n",
    "        \n",
    "        data = pd.DataFrame.from_dict(objects[\"microtubule\"])\n",
    "\n",
    "        width = model.microscope.camera.chip_size_width\n",
    "        height = model.microscope.camera.chip_size_height\n",
    "\n",
    "        lines = data.groupby(\"mt_id\").apply(get_line).reset_index(drop=True)\n",
    "        count = lines.shape[0]\n",
    "\n",
    "        mask = np.zeros((width, height, count), dtype=np.uint8)\n",
    "        for i, line in lines.iterrows():\n",
    "            mask[:, :, i] = draw_line(mask[:, :, i].copy(), line, line_thickness)\n",
    "\n",
    "        # Handle occlusions\n",
    "        handle_occlusion = True\n",
    "        if handle_occlusion:\n",
    "            occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "            for i in range(count - 2, -1, -1):\n",
    "                mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "                occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "\n",
    "        # Save mask as tiff file\n",
    "        mask_path = mask_dir / (basename + \".tif\")\n",
    "        tifffile.imsave(str(mask_path), mask)\n",
    "    \n",
    "parameters = list(itertools.product(snr_range, n_mts_range))\n",
    "p = joblib.Parallel(n_jobs=8, verbose=1)\n",
    "_ = p(map(joblib.delayed(create), parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Manually Annotated Dataset\n",
    "\n",
    "Here we copy a manually annotated dataset to the final training dataset. We also use augmentation on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 1/17 [00:13<03:41, 13.83s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bf02b0903b54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mnew_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_det\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mnew_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_det\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtifffile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_im\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_image\u001b[0;34m(self, image, hooks)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[1;32m    256\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Expected image to have shape (height, width, [channels]), got shape %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maugment_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 )\n\u001b[1;32m    367\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   1427\u001b[0m                         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                         \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                     )\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 )\n\u001b[1;32m    367\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   1895\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages_then_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m                 \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1897\u001b[0;31m                 \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1898\u001b[0m             )\n\u001b[1;32m   1899\u001b[0m             result_else_list = self.else_list.augment_images(\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 )\n\u001b[1;32m    367\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m   1427\u001b[0m                         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m                         \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m                         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1430\u001b[0m                     )\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/meta.py\u001b[0m in \u001b[0;36maugment_images\u001b[0;34m(self, images, parents, hooks)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                     \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 )\n\u001b[1;32m    367\u001b[0m                 \u001b[0;31m# move \"forward\" the random state, so that the next call to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/imgaug/augmenters/geometric.py\u001b[0m in \u001b[0;36m_augment_images\u001b[0;34m(self, images, random_state, parents, hooks)\u001b[0m\n\u001b[1;32m    472\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                     \u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                     \u001b[0mpreserve_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m                 )\n\u001b[1;32m    476\u001b[0m                 \u001b[0;31m# warp changes uint8 to float64, making this necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mwarp\u001b[0;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m    848\u001b[0m                     dims.append(_warp_fast(image[..., dim], matrix,\n\u001b[1;32m    849\u001b[0m                                            \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                                            order=order, mode=mode, cval=cval))\n\u001b[0m\u001b[1;32m    851\u001b[0m                 \u001b[0mwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mskimage/transform/_warps_cy.pyx\u001b[0m in \u001b[0;36mskimage.transform._warps_cy._warp_fast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/nn/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m     \"\"\"Convert the input to an array.\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "manual_data_dir = root_dir / \"Manual Training Dataset\"\n",
    "processed_data_dir = root_dir / \"Manual Training Dataset/Processed\"\n",
    "\n",
    "fnames = [fname.with_suffix(\".tif\") for fname in processed_data_dir.glob(\"*.zip\")]\n",
    "#fnames = fnames[:5]\n",
    "\n",
    "# Sometimes(0.5, ...) applies the given augmenter in 50% of all cases,\n",
    "# e.g. Sometimes(0.5, GaussianBlur(0.3)) would blur roughly every second image.\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "\n",
    "seq = iaa.Sequential(\n",
    "    [\n",
    "        # apply the following augmenters to most images\n",
    "        iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
    "        iaa.Flipud(0.5), # vertically flip 20% of all images\n",
    "        \n",
    "        sometimes(iaa.Affine(\n",
    "            # scale images to 80-120% of their size, individually per axis\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
    "            # translate by -2 to +2 percent (per axis)\n",
    "            translate_percent={\"x\": (-0.02, 0.02), \"y\": (-0.02, 0.02)},\n",
    "            # rotate by -15 to +15 degrees\n",
    "            rotate=(-15, 15),\n",
    "            # shear by -5 to +5 degrees\n",
    "            shear=(-5, 5),\n",
    "            # use nearest neighbour or bilinear interpolation (fast)\n",
    "            order=[0, 1],\n",
    "            # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "            mode=ia.ALL \n",
    "        )),\n",
    "    ])\n",
    "\n",
    "for fname in tqdm.tqdm(fnames, total=len(fnames)):\n",
    "    \n",
    "    basename = fname.stem\n",
    "    \n",
    "    # Copy image file\n",
    "    new_image_path = shutil.copy(fname, image_dir)\n",
    "    \n",
    "    # Convert ZIP rois to JSON rois\n",
    "    rois = read_roi.read_roi_zip(fname.with_suffix(\".zip\"))\n",
    "    objects = convert_rois_to_json(rois)\n",
    "\n",
    "    im = tifffile.imread(str(fname))\n",
    "    width = im.shape[1]\n",
    "    height = im.shape[0]\n",
    "\n",
    "    data = pd.DataFrame.from_dict(objects)\n",
    "    \n",
    "    lines = data.groupby(\"mt_id\").apply(get_line).reset_index(drop=True)\n",
    "    count = lines.shape[0]\n",
    "\n",
    "    mask = np.zeros((height, width, count), dtype=np.uint8)\n",
    "    for i, line in lines.iterrows():\n",
    "        mask[:, :, i] = draw_line(mask[:, :, i].copy(), line, line_thickness)\n",
    "\n",
    "    # Handle occlusions\n",
    "    handle_occlusion = True\n",
    "    if handle_occlusion:\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count - 2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "\n",
    "    # All object are of class \"1\" for a microtubule\n",
    "    class_ids = np.repeat(1, mask.shape[-1])\n",
    "            \n",
    "    # Save mask as tiff file\n",
    "    mask_path = mask_dir / (basename + \".tif\")\n",
    "    tifffile.imsave(str(mask_path), mask)\n",
    "    \n",
    "    # Save class ids \n",
    "    class_ids_path = class_dir / (basename + \".csv\")\n",
    "    pd.Series(class_ids).to_csv(class_ids_path, index=False)\n",
    "    \n",
    "    # If th mask is too lage we just copy the datum instead of augmenting it to avoid memory error.\n",
    "    if mask.shape[-1] < 500:\n",
    "        \n",
    "        # Augmentation: we create new images from the above one.\n",
    "        for i in range(n_augm):\n",
    "            new_image_path = image_dir / (basename + f\"_AUGMENTED_{i}.tif\")\n",
    "            new_mask_path = mask_dir / (basename + f\"_AUGMENTED_{i}.tif\")\n",
    "            new_class_ids_path = class_dir / (basename + f\"_AUGMENTED_{i}.csv\")\n",
    "\n",
    "            seq_det = seq.to_deterministic()\n",
    "\n",
    "            new_im = seq_det.augment_image(im)\n",
    "            new_mask = seq_det.augment_image(mask)\n",
    "\n",
    "            tifffile.imsave(str(new_image_path), new_im)\n",
    "            tifffile.imsave(str(new_mask_path), new_mask)\n",
    "            pd.Series(class_ids).to_csv(new_class_ids_path, index=False)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        for i in range(n_augm):\n",
    "            new_image_path = image_dir / (basename + f\"_AUGMENTED_{i}.tif\")\n",
    "            new_mask_path = mask_dir / (basename + f\"_AUGMENTED_{i}.tif\")\n",
    "            new_class_ids_path = class_dir / (basename + f\"_AUGMENTED_{i}.csv\")\n",
    "            \n",
    "            shutil.copyfile(str(fname), str(new_image_path))\n",
    "            shutil.copyfile(str(mask_path), str(new_mask_path))\n",
    "            shutil.copyfile(str(class_ids_path), str(new_class_ids_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
