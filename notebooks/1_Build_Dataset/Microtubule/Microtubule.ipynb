{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtubule Dataset\n",
    "\n",
    "- We use [`anamic`](https://github.com/hadim/anamic) to simulate microscopy images of microtubule.\n",
    "- In short, each dimer positions is computed in 3D then projected on a 2D plan. Dimers are then convoled with a PSF and some noise is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install --upgrade https://github.com/hadim/anamic/archive/88bdf3e08bee5711d73613b3aa5ace9297c0e5ef.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadim/conda/envs/nn/lib/python3.6/site-packages/anamic/transformations.py:1916: UserWarning: No module named 'anamic._transformations'\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sys; sys.path.append(\"../../../\")\n",
    "import maskflow\n",
    "\n",
    "import anamic\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/Microtubule\")\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = maskflow.config.load_config(\"config.yaml\")\n",
    "\n",
    "# Copy config next to data folder\n",
    "maskflow.config.save_config(config, root_dir / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build microtubule images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Parameters\n",
    "pixel_size = 110  # nm/pixel\n",
    "image_size_pixel = 512\n",
    "n_images = 1000\n",
    "\n",
    "# Per image parameters\n",
    "image_parameters = {}\n",
    "image_parameters['n_mt'] = {}\n",
    "image_parameters['n_mt']['values'] = np.arange(50, 100)\n",
    "#image_parameters['n_mt']['values'] = np.arange(2, 3)\n",
    "image_parameters['n_mt']['prob'] = 'uniform'\n",
    "\n",
    "image_parameters['signal_mean'] = {}\n",
    "image_parameters['signal_mean']['values'] = {'loc': 700, 'scale': 20}\n",
    "image_parameters['signal_mean']['prob'] = 'normal'\n",
    "\n",
    "image_parameters['signal_std'] = {}\n",
    "image_parameters['signal_std']['values'] = {'loc': 100, 'scale': 5}\n",
    "image_parameters['signal_std']['prob'] = 'normal'\n",
    "\n",
    "image_parameters['bg_mean'] = {}\n",
    "image_parameters['bg_mean']['values'] = {'loc': 500, 'scale': 30}\n",
    "image_parameters['bg_mean']['prob'] = 'normal'\n",
    "\n",
    "image_parameters['bg_std'] = {}\n",
    "image_parameters['bg_std']['values'] = {'loc': 24, 'scale': 5}\n",
    "image_parameters['bg_std']['prob'] = 'normal'\n",
    "\n",
    "image_parameters['noise_factor'] = {}\n",
    "image_parameters['noise_factor']['values'] = np.arange(0.8, 2.0, 0.1)\n",
    "image_parameters['noise_factor']['prob'] = 'uniform'\n",
    "\n",
    "# Per microtubule parameters\n",
    "microtubule_parameters = {}\n",
    "\n",
    "microtubule_parameters['n_pf'] = {}\n",
    "microtubule_parameters['n_pf']['values'] = [11, 12, 13, 14, 15]\n",
    "microtubule_parameters['n_pf']['prob'] = [0.05, 0.05, 0.3, 0.1, 0.5]\n",
    "\n",
    "microtubule_parameters['mt_length_nm'] = {}\n",
    "microtubule_parameters['mt_length_nm']['values'] = np.arange(500, 7000)\n",
    "microtubule_parameters['mt_length_nm']['prob'] = 'uniform'\n",
    "\n",
    "microtubule_parameters['taper_length_nm'] = {}\n",
    "microtubule_parameters['taper_length_nm']['values'] = np.arange(0, 3000)\n",
    "microtubule_parameters['taper_length_nm']['prob'] = 'uniform'\n",
    "\n",
    "microtubule_parameters['labeling_ratio'] = {}\n",
    "microtubule_parameters['labeling_ratio']['values'] = [0.08, 0.09, 0.10, 0.11, 0.12, 0.13]\n",
    "microtubule_parameters['labeling_ratio']['prob'] = 'uniform'\n",
    "\n",
    "microtubule_parameters['pixel_size'] = pixel_size\n",
    "microtubule_parameters['x_offset'] = 2000  # nm\n",
    "microtubule_parameters['y_offset'] = 2000  # nm\n",
    "microtubule_parameters['psf_size'] = 135  # nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadim/conda/envs/nn/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a310db7253b540488af2e85a22fab5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert config['INPUT']['MAX_SIZE_TRAIN'] == image_size_pixel\n",
    "\n",
    "training_size = 0.8  # From 0 to 1\n",
    "png_compression_level = 0  # From 0 to 9\n",
    "\n",
    "len_dataset = n_images\n",
    "\n",
    "train_ids, _ = train_test_split(np.arange(0, len_dataset), train_size=training_size)\n",
    "\n",
    "train_dir = data_dir / \"train_dataset\"\n",
    "train_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "test_dir = data_dir / \"test_dataset\"\n",
    "test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_annotations_path = data_dir / \"train_annotations.json\"\n",
    "test_annotations_path = data_dir / \"test_annotations.json\"\n",
    "\n",
    "train_annotations = maskflow.dataset.get_base_annotations(['microtubule'], supercategory=\"cytoskeleton\")\n",
    "test_annotations = maskflow.dataset.get_base_annotations(['microtubule'], supercategory=\"cytoskeleton\")\n",
    "\n",
    "worker_args = []\n",
    "for i in range(n_images):\n",
    "    worker_args.append({'i': i, 'image_size_pixel': image_size_pixel, 'pixel_size': pixel_size,\n",
    "                        'microtubule_parameters': microtubule_parameters,\n",
    "                        'image_parameters': image_parameters.copy(),\n",
    "                        'png_compression_level': png_compression_level})\n",
    "        \n",
    "        \n",
    "def worker(i, image_size_pixel, pixel_size, microtubule_parameters, image_parameters, png_compression_level):\n",
    "    \n",
    "    image, masks = anamic.fov.create_fov(image_size_pixel, pixel_size, microtubule_parameters, image_parameters)\n",
    "    assert image.shape[-2:] == (image_size_pixel, image_size_pixel)\n",
    "    \n",
    "    # Get the annotation in the COCO format.\n",
    "    basename = f\"microtubules_{i:05d}.png\"\n",
    "\n",
    "    # Only keep masks with more than 5 pixels\n",
    "    mask_to_keep = masks.sum(axis=-1).sum(axis=-1) > 5\n",
    "    masks = masks[mask_to_keep]\n",
    "    \n",
    "    if masks.shape[0] == 0:\n",
    "        return None\n",
    "    \n",
    "    class_ids = np.ones(masks.shape[0])\n",
    "    \n",
    "    image = exposure.rescale_intensity(image, out_range='uint8')\n",
    "    image = image.astype('uint8')\n",
    "\n",
    "    image_info, image_annotations = maskflow.dataset.get_annotations(i, basename, image, masks, class_ids)\n",
    "    \n",
    "    if i in train_ids:\n",
    "        image_path = train_dir / basename\n",
    "        is_train = True\n",
    "    else:\n",
    "        image_path = test_dir / basename\n",
    "        is_train = False\n",
    "        \n",
    "    Image.fromarray(image, mode='L').save(str(image_path), compress_level=png_compression_level)\n",
    "    return is_train, image_info, image_annotations\n",
    "\n",
    "executor_factory = anamic.utils.parallel_executor(use_bar='tqdm', n_jobs=-1)(total=len(worker_args))\n",
    "executors = [executor_factory(delayed(worker)(**worker_arg) for worker_arg in worker_args)]\n",
    "\n",
    "for executor in executors:\n",
    "    for results in executor:\n",
    "        if results:\n",
    "            is_train, image_info, image_annotations = results\n",
    "            if is_train:\n",
    "                train_annotations['images'].append(image_info)\n",
    "                train_annotations['annotations'].extend(image_annotations)\n",
    "            else:\n",
    "                test_annotations['images'].append(image_info)\n",
    "                test_annotations['annotations'].extend(image_annotations)\n",
    "    \n",
    "maskflow.dataset.save_annotations(train_annotations, train_annotations_path)\n",
    "maskflow.dataset.save_annotations(test_annotations, test_annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['SOLVER']['IMS_PER_BATCH'] = 1\n",
    "config['TEST']['IMS_PER_BATCH'] = 1\n",
    "\n",
    "# Number of batch to load\n",
    "n = 4\n",
    "\n",
    "# Load some data\n",
    "data_loader = maskflow.dataset.get_data_loader(config, data_dir, is_train=True)\n",
    "some_data = [iter(data_loader).next() for _ in range(n)]\n",
    "\n",
    "# Retrieve category's names\n",
    "categories = data_loader.dataset.coco.cats\n",
    "\n",
    "for batch_image, batch_target, batch_idx in some_data:\n",
    "    maskflow.viz.batch_display_top_masks(batch_image, batch_target, batch_idx, categories,\n",
    "                                         basesize=7, limit=1, cmap=\"PuBu_r\",\n",
    "                                         pixel_mean=config['INPUT']['PIXEL_MEAN'],\n",
    "                                         pixel_std=config['INPUT']['PIXEL_STD'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
