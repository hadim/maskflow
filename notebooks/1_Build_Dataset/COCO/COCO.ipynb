{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from pycocotools import coco\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "import maskflow\n",
    "\n",
    "import coco_utils\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/COCO\")\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "annotations_dir = data_dir / \"annotations\"\n",
    "\n",
    "params = maskflow.load_parameters(\"parameters.yml\")\n",
    "class_names = params[\"CLASS_NAMES\"]\n",
    "\n",
    "# Copy config next to data folder\n",
    "maskflow.save_parameters(params, root_dir / \"parameters.yml\")\n",
    "\n",
    "if not annotations_dir.is_dir():\n",
    "    coco_utils.download_cocodataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataset to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_set = \"val\"\n",
    "coco_year = 2017\n",
    "\n",
    "tfrecord_path = data_dir / \"validation_data.tfrecord\"\n",
    "\n",
    "max_image = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataset\n",
    "\n",
    "(Can be long...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.50s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 62/1000 [00:31<07:58,  1.96it/s]"
     ]
    }
   ],
   "source": [
    "annotations_path = annotations_dir / f\"instances_{coco_set}{coco_year}.json\"\n",
    "coco_data = coco.COCO(annotation_file=str(annotations_path))\n",
    "\n",
    "class_names = [value[\"name\"] for _, value in coco_data.cats.items()]\n",
    "params[\"CLASS_NAMES\"] = class_names\n",
    "maskflow.save_parameters(params, \"parameters.yml\")\n",
    "maskflow.save_parameters(params, root_dir / \"parameters.yml\")\n",
    "\n",
    "tfrecord_writer = tf.python_io.TFRecordWriter(str(tfrecord_path))\n",
    "\n",
    "n = len(coco_data.imgs)\n",
    "for i, image_id in enumerate(tqdm.tqdm(coco_data.getImgIds()[:max_image], total=max_image)):\n",
    "    \n",
    "    image_info = coco_data.loadImgs(ids=[image_id])[0]\n",
    "    \n",
    "    # Download image\n",
    "    image = Image.open(urllib.request.urlopen(image_info[\"coco_url\"]))\n",
    "    image = np.array(image)\n",
    "    \n",
    "    anns = coco_data.imgToAnns[image_id]\n",
    "    \n",
    "    class_ids = []\n",
    "    masks = []\n",
    "\n",
    "    for ann in anns:\n",
    "        # Get class id\n",
    "        class_name = coco_data.loadCats(ids=[ann[\"category_id\"]])[0][\"name\"]\n",
    "        class_id = class_names.index(class_name) + 1\n",
    "        class_ids.append(class_id)\n",
    "\n",
    "        # Get mask\n",
    "        mask = coco_data.annToMask(ann)\n",
    "        assert mask.shape == image.shape[:2]\n",
    "        masks.append(mask)\n",
    "\n",
    "    class_ids = np.array(class_ids)\n",
    "    masks = np.array(masks)\n",
    "    \n",
    "    tf_example = maskflow.create_tf_example(i, image_info[\"file_name\"], image, masks, class_ids)\n",
    "    tfrecord_writer.write(tf_example.SerializeToString())\n",
    "    \n",
    "tfrecord_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some images with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve some data\n",
    "images, annotations = maskflow.get_data(tfrecord_path, n=4, shuffle=True)\n",
    "\n",
    "# Display them\n",
    "maskflow.batch_display_top_masks(images, annotations[\"masks\"], annotations[\"class_ids\"], params[\"CLASS_NAMES\"], limit=3, basesize=40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
