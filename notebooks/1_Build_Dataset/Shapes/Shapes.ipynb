{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a toy shapes dataset. Strongly inspired from [this implementation](https://github.com/matterport/Mask_RCNN/blob/cbff80f3e3f653a9eeee43d0d383a0385aba546b/samples/shapes/shapes.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "import tifffile\n",
    "\n",
    "import sys; sys.path.append(\"../../../\")\n",
    "import maskflow\n",
    "\n",
    "import utils\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/Shapes\")\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "config = maskflow.load_config(\"config.yaml\")\n",
    "\n",
    "# Copy config next to data folder\n",
    "maskflow.save_config(config, root_dir / \"config.yaml\")\n",
    "\n",
    "class_names = [\"circle\", \"triangle\", \"square\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "100%|██████████| 50/50 [00:00<00:00, 115.63it/s]\n"
     ]
    }
   ],
   "source": [
    "height = config[\"INPUT\"][\"MAX_SIZE_TRAIN\"]\n",
    "width = config[\"INPUT\"][\"MAX_SIZE_TRAIN\"]\n",
    "count = 50\n",
    "max_n_per_image = 10\n",
    "training_size = 0.9\n",
    "\n",
    "train_ids, _ = train_test_split(np.arange(0, count), train_size=training_size)\n",
    "\n",
    "train_dir = data_dir / \"train_dataset\"\n",
    "train_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "test_dir = data_dir / \"test_dataset\"\n",
    "test_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_annotations_path = data_dir / \"train_annotations.json\"\n",
    "test_annotations_path = data_dir / \"test_annotations.json\"\n",
    "\n",
    "train_annotations = maskflow.get_base_annotations(class_names, supercategory=\"shape\")\n",
    "test_annotations = maskflow.get_base_annotations(class_names, supercategory=\"shape\")\n",
    "\n",
    "annotation_id = 1\n",
    "\n",
    "for image_id in tqdm.trange(count):\n",
    "    # Generate image specification\n",
    "    bg_color, shapes = utils.random_image(height, width, max_n_per_image, class_names)\n",
    "    \n",
    "    # Generate the image\n",
    "    image = utils.generate_image(bg_color, height, width, shapes)\n",
    "    \n",
    "    # Generate the mask\n",
    "    mask, class_ids = utils.generate_mask(bg_color, height, width, shapes, class_names)\n",
    "    \n",
    "    basename = f\"toy_{image_id:04d}.tif\"\n",
    "    \n",
    "    # Get the annotation in the COCO format.\n",
    "    image_info, image_annotations = maskflow.get_annotations(image_id, basename, image, mask, class_ids)\n",
    "    \n",
    "    if image_id in train_ids:\n",
    "        image_path = train_dir / basename\n",
    "        train_annotations[\"images\"].append(image_info)\n",
    "        train_annotations[\"annotations\"].extend(image_annotations)\n",
    "    else:\n",
    "        image_path = test_dir / basename\n",
    "        test_annotations[\"images\"].append(image_info)\n",
    "        test_annotations[\"annotations\"].extend(image_annotations)\n",
    "    \n",
    "    tifffile.imsave(str(image_path), image)\n",
    "    \n",
    "maskflow.save_annotations(train_annotations, train_annotations_path)\n",
    "maskflow.save_annotations(test_annotations, test_annotations_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some images with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "data_loader = maskflow.get_data_loader(config, data_dir, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [data_loader.__iter__() for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of prompt_toolkit.layout.containers failed: Traceback (most recent call last):\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 376, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/prompt_toolkit/layout/containers.py\", line 1145, in <module>\n",
      "    _in_insert_mode = vi_insert_mode | emacs_insert_mode\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/prompt_toolkit/filters/base.py\", line 39, in __or__\n",
      "    return _or_cache[self, other]\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/prompt_toolkit/filters/base.py\", line 90, in __missing__\n",
      "    assert isinstance(b, Filter), 'Expecting filter, got %r' % b\n",
      "AssertionError: Expecting filter, got Condition(<function emacs_insert_mode at 0x7fd533e49158>)\n",
      "]\n",
      "[autoreload of prompt_toolkit.formatted_text.base failed: Traceback (most recent call last):\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 392, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 329, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 287, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 329, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 265, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: __repr__() requires a code object with 0 free vars, not 1\n",
      "]\n",
      "[autoreload of prompt_toolkit.shortcuts failed: Traceback (most recent call last):\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 376, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/hadim/local/conda/envs/nn/lib/python3.6/site-packages/prompt_toolkit/shortcuts/__init__.py\", line 4, in <module>\n",
      "    from .utils import print_formatted_text, print_container, clear, set_title, clear_title\n",
      "ImportError: cannot import name 'print_container'\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataloader._DataLoaderIter at 0x7fd49dedeeb8>,\n",
       " <torch.utils.data.dataloader._DataLoaderIter at 0x7fd49deec5f8>,\n",
       " <torch.utils.data.dataloader._DataLoaderIter at 0x7fd49dc6b198>,\n",
       " <torch.utils.data.dataloader._DataLoaderIter at 0x7fd49dc73390>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'maskflow' has no attribute 'get_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-be824bd91eb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Retrieve some data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaskflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Display them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'maskflow' has no attribute 'get_data'"
     ]
    }
   ],
   "source": [
    "# Select the training dataset\n",
    "tfrecord_path = data_dir / \"training_data.tfrecord\"\n",
    "\n",
    "# Retrieve some data\n",
    "images, annotations = maskflow.get_data(data_loader, n=4, shuffle=True)\n",
    "\n",
    "# Display them\n",
    "maskflow.batch_display_top_masks(images, annotations[\"masks\"], annotations[\"class_ids\"], class_names, limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist_info": {
   "gist_id": null,
   "gist_url": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
