{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Toy Shape Dataset\n",
    "\n",
    " - A toy shapes dataset: small resolution image composed of squares, circles an triangles.\n",
    " - Strongly inspired from [this implementation](https://github.com/matterport/Mask_RCNN/blob/cbff80f3e3f653a9eeee43d0d383a0385aba546b/samples/shapes/shapes.py).\n",
    " - The [config.yaml file](./config.yaml) should be able to train the dataset composed of 50 images in less than 10 minutes on a regular GPU with a **mAP@[0.5:0.95] of ~70%**.\n",
    " \n",
    "This dataset is ideal for debugging and educational purpose.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "\n",
    "import sys; sys.path.append(\"../../../\")\n",
    "import maskflow\n",
    "\n",
    "import utils\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/Shapes\")\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the configuration.\n",
    "config = maskflow.load_config(\"config.yaml\")\n",
    "\n",
    "# Copy config next to data folder.\n",
    "maskflow.save_config(config, root_dir / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 284.81it/s]\n"
     ]
    }
   ],
   "source": [
    "height = config[\"DATASET\"][\"IMAGE_SIZE\"]\n",
    "width = config[\"DATASET\"][\"IMAGE_SIZE\"]\n",
    "class_names = config[\"DATASET\"][\"CLASS_NAMES\"]\n",
    "\n",
    "count = 50\n",
    "min_n_per_image = 1\n",
    "max_n_per_image = 4\n",
    "training_size = 0.9  # From 0 to 1\n",
    "\n",
    "image_format = \"png\"\n",
    "masks_format = \"png\"\n",
    "\n",
    "train_ids, _ = train_test_split(np.arange(0, count), train_size=training_size)\n",
    "\n",
    "train_features_example = []\n",
    "test_features_example = []\n",
    "\n",
    "train_file_path = data_dir / \"train.tfrecords\"\n",
    "test_file_path = data_dir / \"test.tfrecords\"\n",
    "\n",
    "for image_id in tqdm.trange(count):\n",
    "    # Generate image specification\n",
    "    bg_color, shapes = utils.random_image(height, width, min_n_per_image, max_n_per_image, class_names)\n",
    "    \n",
    "    # Generate the image\n",
    "    image = utils.generate_image(bg_color, height, width, shapes)\n",
    "    \n",
    "    # Generate the masks\n",
    "    masks, label_ids = utils.generate_mask(bg_color, height, width, shapes, class_names)\n",
    "    \n",
    "    # Get a list of class from the object label ids.\n",
    "    label_names = [class_names[class_id].encode(\"utf8\") for class_id in label_ids]\n",
    "    \n",
    "    # Get bounding boxes from masks.\n",
    "    bboxes = maskflow.bbox.from_masks(masks)\n",
    "    \n",
    "    filename = f\"toy_{image_id:04d}.png\"\n",
    "    \n",
    "    build_features_args = {}\n",
    "    build_features_args['image'] = image\n",
    "    build_features_args['image_id'] = image_id\n",
    "    build_features_args['filename'] = filename\n",
    "    build_features_args['image_format'] = image_format\n",
    "    build_features_args['bboxes'] = bboxes\n",
    "    build_features_args['masks'] = masks\n",
    "    build_features_args['label_ids'] = label_ids\n",
    "    build_features_args['label_names'] = label_names\n",
    "    build_features_args['masks_format'] = masks_format\n",
    "    features_dict = maskflow.dataset.build_features_dict(**build_features_args)\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features_dict))\n",
    "    \n",
    "    if image_id in train_ids:\n",
    "        train_features_example.append(example)\n",
    "    else:\n",
    "        test_features_example.append(example)\n",
    "        \n",
    "# Write examples to TFRecord files.\n",
    "with tf.io.TFRecordWriter(str(train_file_path)) as writer:\n",
    "    for example in train_features_example:\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "with tf.io.TFRecordWriter(str(test_file_path)) as writer:\n",
    "    for example in test_features_example:\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some images with their masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- allow iamge without bboxes\n",
    "- convert to bboxes\n",
    "- pad datum to be able to batch\n",
    "- make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89a5db316d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaskflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_preprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/hadim/Drive/Documents/Code/Postdoc/maskflow/maskflow/dataset/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(tfrecord_path, config, do_preprocess, with_bboxes, with_label_names, with_label_ids, with_masks)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_preprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DATASET'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MAX_NUM_INSTANCES'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "train_dataset = maskflow.dataset.parse(train_file_path, config, do_preprocess=True)\n",
    "\n",
    "for feature in train_dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in train_dataset.batch(10):\n",
    "    print(\"p\")\n",
    "feature['masks'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_dataset.shuffle(1000).take(10)\n",
    "features = [feature for feature in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = features[0]\n",
    "\n",
    "image = feature['image'].numpy()\n",
    "masks = feature['masks'].numpy()\n",
    "bboxes = feature['bboxes'].numpy()\n",
    "label_ids = feature['label_ids'].numpy()\n",
    "label_names = feature['label_names'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_display_top_masks(batch_image, batch_target, batch_idx, categories,\n",
    "                            basesize=14, limit=4, cmap=\"PuBu_r\",\n",
    "                            pixel_mean=[0, 0, 0], pixel_std=[1, 1, 1]):\n",
    "    \"\"\"Display the given images and the top few class masks.\n",
    "\n",
    "    See `maskflow.display_top_masks`.\n",
    "    \"\"\"\n",
    "    for image, target, idx in zip(batch_image.tensors, batch_target, batch_idx):\n",
    "        image = image.numpy().copy().swapaxes(0, 2).swapaxes(0, 1)\n",
    "\n",
    "        # Undo image normalization\n",
    "        image += np.array(pixel_mean)\n",
    "        image *= np.array(pixel_std)\n",
    "        image = image.astype('uint8')\n",
    "\n",
    "        labels = target.get_field('labels')\n",
    "        masks = target.get_field('masks')\n",
    "\n",
    "        display_top_masks(image, masks, labels, categories, basesize=basesize, limit=limit, cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of batch to load\n",
    "n = 1\n",
    "\n",
    "# Load some data\n",
    "data_loader = maskflow.dataset.get_data_loader(config, data_dir, is_train=True)\n",
    "some_data = [iter(data_loader).next() for _ in range(n)]\n",
    "\n",
    "# Retrieve category's names\n",
    "categories = data_loader.dataset.coco.cats\n",
    "\n",
    "for batch_image, batch_target, batch_idx in some_data:\n",
    "    maskflow.viz.batch_display_top_masks(train_dataset, basesize=14, limit=3, cmap=\"PuBu_r\")"
   ]
  }
 ],
 "metadata": {
  "gist_info": {
   "gist_id": null,
   "gist_url": null
  },
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
