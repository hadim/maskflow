{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Toy Shape Dataset\n",
    "\n",
    " - A toy shapes dataset: small resolution image composed of squares, circles an triangles.\n",
    " - Strongly inspired from [this implementation](https://github.com/matterport/Mask_RCNN/blob/cbff80f3e3f653a9eeee43d0d383a0385aba546b/samples/shapes/shapes.py).\n",
    " - The [config.yaml file](./config.yaml) should be able to train the dataset composed of 50 images in less than 10 minutes on a regular GPU with a **mAP@[0.5:0.95] of ~70%**.\n",
    " \n",
    "This dataset is ideal for debugging and educational purpose.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "\n",
    "import sys; sys.path.append(\"../../../\")\n",
    "import maskflow\n",
    "\n",
    "import utils\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/Shapes\")\n",
    "\n",
    "data_dir = root_dir / \"Data\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the configuration.\n",
    "config = maskflow.load_config(\"config.yaml\")\n",
    "\n",
    "# Copy config next to data folder.\n",
    "maskflow.save_config(config, root_dir / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = config[\"DATASET\"][\"IMAGE_SIZE\"]\n",
    "width = config[\"DATASET\"][\"IMAGE_SIZE\"]\n",
    "class_names = config[\"DATASET\"][\"CLASS_NAMES\"]\n",
    "\n",
    "count = 50\n",
    "min_n_per_image = 1\n",
    "max_n_per_image = 4\n",
    "training_size = 0.9  # From 0 to 1\n",
    "\n",
    "image_format = \"png\"\n",
    "masks_format = \"png\"\n",
    "\n",
    "train_ids, _ = train_test_split(np.arange(0, count), train_size=training_size)\n",
    "\n",
    "train_features_example = []\n",
    "test_features_example = []\n",
    "\n",
    "train_file_path = data_dir / \"train.tfrecords\"\n",
    "test_file_path = data_dir / \"test.tfrecords\"\n",
    "\n",
    "for image_id in tqdm.trange(count):\n",
    "    # Generate image specification\n",
    "    bg_color, shapes = utils.random_image(height, width, min_n_per_image, max_n_per_image, class_names)\n",
    "    \n",
    "    # Generate the image\n",
    "    image = utils.generate_image(bg_color, height, width, shapes)\n",
    "    \n",
    "    # Generate the masks\n",
    "    masks, label_ids = utils.generate_mask(bg_color, height, width, shapes, class_names)\n",
    "    \n",
    "    # Get a list of class from the object label ids.\n",
    "    label_names = [class_names[class_id].encode(\"utf8\") for class_id in label_ids]\n",
    "    \n",
    "    # Get bounding boxes from masks.\n",
    "    bboxes = maskflow.bbox.from_masks(masks)\n",
    "    \n",
    "    filename = f\"toy_{image_id:04d}.png\"\n",
    "    \n",
    "    build_features_args = {}\n",
    "    build_features_args['image'] = image\n",
    "    build_features_args['image_id'] = image_id\n",
    "    build_features_args['filename'] = filename\n",
    "    build_features_args['image_format'] = image_format\n",
    "    build_features_args['bboxes'] = bboxes\n",
    "    build_features_args['masks'] = masks\n",
    "    build_features_args['label_ids'] = label_ids\n",
    "    build_features_args['label_names'] = label_names\n",
    "    build_features_args['masks_format'] = masks_format\n",
    "    features_dict = maskflow.dataset.build_features_dict(**build_features_args)\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features_dict))\n",
    "    \n",
    "    if image_id in train_ids:\n",
    "        train_features_example.append(example)\n",
    "    else:\n",
    "        test_features_example.append(example)\n",
    "        \n",
    "# Write examples to TFRecord files.\n",
    "with tf.io.TFRecordWriter(str(train_file_path)) as writer:\n",
    "    for example in train_features_example:\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "with tf.io.TFRecordWriter(str(test_file_path)) as writer:\n",
    "    for example in test_features_example:\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize some images with their masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- allow iamge without bboxes\n",
    "- convert to bboxes\n",
    "- pad datum to be able to batch\n",
    "- make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = maskflow.dataset.parse(train_file_path)\n",
    "for datum in train_dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_ids': <tf.Tensor: id=31265, shape=(3, 4), dtype=int64, numpy=\n",
       " array([[ 2,  2,  1, -1],\n",
       "        [ 1,  1, -1, -1],\n",
       "        [ 0,  2,  1,  1]])>,\n",
       " 'label_names': <tf.Tensor: id=31266, shape=(3, 4), dtype=string, numpy=\n",
       " array([[b'square', b'square', b'triangle', b''],\n",
       "        [b'triangle', b'triangle', b'', b''],\n",
       "        [b'circle', b'square', b'triangle', b'triangle']], dtype=object)>}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _fn(datum):\n",
    "    small = {}\n",
    "    #small['bboxes'] = datum['bboxes']\n",
    "    #small['masks'] = datum['masks']\n",
    "    small['label_ids'] = datum['label_ids']\n",
    "    small['label_names'] = datum['label_names']\n",
    "    return small\n",
    "    \n",
    "test = train_dataset.map(_fn)\n",
    "\n",
    "padded_shapes = {}\n",
    "#padded_shapes['bboxes'] = [-1, None, None]\n",
    "#padded_shapes['masks'] = [-1, None, None]\n",
    "padded_shapes['label_ids'] = [-1]\n",
    "padded_shapes['label_names'] = [-1]\n",
    "\n",
    "padding_values = {}\n",
    "#padding_values['bboxes'] = np.nan\n",
    "#padding_values['masks'] = np.nan\n",
    "padding_values['label_ids'] = tf.constant(-1, dtype=tf.int64)\n",
    "padding_values['label_names'] = \"\"\n",
    "\n",
    "test = test.padded_batch(7, padded_shapes=padded_shapes, padding_values=padding_values)\n",
    "\n",
    "for datum in test:\n",
    "    pass\n",
    "\n",
    "datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_ids': <tf.Tensor: id=26964, shape=(5, 4), dtype=int64, numpy=\n",
       " array([[1, 0, 0, 0],\n",
       "        [2, 2, 2, 0],\n",
       "        [1, 0, 0, 2],\n",
       "        [1, 1, 1, 0],\n",
       "        [2, 0, 0, 0]])>}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot batch tensors with different shapes in component 0. First element had shape [4,4] and element 1 had shape [1,4]. [Op:IteratorGetNextSync]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-bd246f2fb278>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \"\"\"\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next_sync\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2118\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2120\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/conda/envs/tf/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [4,4] and element 1 had shape [1,4]. [Op:IteratorGetNextSync]"
     ]
    }
   ],
   "source": [
    "for datum in train_dataset.take(10).batch(2):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(datum['masks'].numpy().max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(datum['image'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of batch to load\n",
    "n = 1\n",
    "\n",
    "# Load some data\n",
    "data_loader = maskflow.dataset.get_data_loader(config, data_dir, is_train=True)\n",
    "some_data = [iter(data_loader).next() for _ in range(n)]\n",
    "\n",
    "# Retrieve category's names\n",
    "categories = data_loader.dataset.coco.cats\n",
    "\n",
    "for batch_image, batch_target, batch_idx in some_data:\n",
    "    maskflow.viz.batch_display_top_masks(train_dataset, basesize=14, limit=3, cmap=\"PuBu_r\")"
   ]
  }
 ],
 "metadata": {
  "gist_info": {
   "gist_id": null,
   "gist_url": null
  },
  "kernelspec": {
   "display_name": "Python 3 - [tf-sde]",
   "language": "python",
   "name": "tf-sde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
