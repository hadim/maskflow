{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl.testing import parameterized\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.meta_architectures import faster_rcnn_meta_arch_test_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<ipython-input-2-8a12e557000c>, line 104)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-8a12e557000c>\"\u001b[0;36m, line \u001b[0;32m104\u001b[0m\n\u001b[0;31m    @parameterized.parameters(\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class FasterRCNNMetaArchTest(\n",
    "    faster_rcnn_meta_arch_test_lib.FasterRCNNMetaArchTestBase,\n",
    "    parameterized.TestCase):\n",
    "\n",
    "    def test_postprocess_second_stage_only_inference_mode_with_masks(self):\n",
    "        model = self._build_model(\n",
    "            is_training=False, number_of_stages=2, second_stage_batch_size=6)\n",
    "\n",
    "        batch_size = 2\n",
    "        total_num_padded_proposals = batch_size * model.max_num_proposals\n",
    "        proposal_boxes = tf.constant(\n",
    "            [[[1, 1, 2, 3],\n",
    "              [0, 0, 1, 1],\n",
    "              [.5, .5, .6, .6],\n",
    "              4*[0], 4*[0], 4*[0], 4*[0], 4*[0]],\n",
    "             [[2, 3, 6, 8],\n",
    "              [1, 2, 5, 3],\n",
    "              4*[0], 4*[0], 4*[0], 4*[0], 4*[0], 4*[0]]], dtype=tf.float32)\n",
    "        num_proposals = tf.constant([3, 2], dtype=tf.int32)\n",
    "        refined_box_encodings = tf.zeros(\n",
    "            [total_num_padded_proposals, model.num_classes, 4], dtype=tf.float32)\n",
    "        class_predictions_with_background = tf.ones(\n",
    "            [total_num_padded_proposals, model.num_classes+1], dtype=tf.float32)\n",
    "        image_shape = tf.constant([batch_size, 36, 48, 3], dtype=tf.int32)\n",
    "\n",
    "        mask_height = 2\n",
    "        mask_width = 2\n",
    "        mask_predictions = 30. * tf.ones(\n",
    "            [total_num_padded_proposals, model.num_classes,\n",
    "             mask_height, mask_width], dtype=tf.float32)\n",
    "        exp_detection_masks = np.array([[[[1, 1], [1, 1]],\n",
    "                                         [[1, 1], [1, 1]],\n",
    "                                         [[1, 1], [1, 1]],\n",
    "                                         [[1, 1], [1, 1]],\n",
    "                                         [[1, 1], [1, 1]]],\n",
    "                                        [[[1, 1], [1, 1]],\n",
    "                                         [[1, 1], [1, 1]],\n",
    "                                         [[1, 1], [1, 1]],\n",
    "                                         [[1, 1], [1, 1]],\n",
    "                                         [[0, 0], [0, 0]]]])\n",
    "\n",
    "        _, true_image_shapes = model.preprocess(tf.zeros(image_shape))\n",
    "        detections = model.postprocess({\n",
    "            'refined_box_encodings': refined_box_encodings,\n",
    "            'class_predictions_with_background': class_predictions_with_background,\n",
    "            'num_proposals': num_proposals,\n",
    "            'proposal_boxes': proposal_boxes,\n",
    "            'image_shape': image_shape,\n",
    "            'mask_predictions': mask_predictions\n",
    "        }, true_image_shapes)\n",
    "        with self.test_session() as sess:\n",
    "          detections_out = sess.run(detections)\n",
    "          self.assertAllEqual(detections_out['detection_boxes'].shape, [2, 5, 4])\n",
    "          self.assertAllClose(detections_out['detection_scores'],\n",
    "                              [[1, 1, 1, 1, 1], [1, 1, 1, 1, 0]])\n",
    "          self.assertAllClose(detections_out['detection_classes'],\n",
    "                              [[0, 0, 0, 1, 1], [0, 0, 1, 1, 0]])\n",
    "          self.assertAllClose(detections_out['num_detections'], [5, 4])\n",
    "          self.assertAllClose(detections_out['detection_masks'],\n",
    "                              exp_detection_masks)\n",
    "          self.assertTrue(np.amax(detections_out['detection_masks'] <= 1.0))\n",
    "          self.assertTrue(np.amin(detections_out['detection_masks'] >= 0.0))\n",
    "\n",
    "    def test_postprocess_second_stage_only_inference_mode_with_shared_boxes(self):\n",
    "        model = self._build_model(\n",
    "            is_training=False, number_of_stages=2, second_stage_batch_size=6)\n",
    "\n",
    "        batch_size = 2\n",
    "        total_num_padded_proposals = batch_size * model.max_num_proposals\n",
    "        proposal_boxes = tf.constant(\n",
    "            [[[1, 1, 2, 3],\n",
    "              [0, 0, 1, 1],\n",
    "              [.5, .5, .6, .6],\n",
    "              4*[0], 4*[0], 4*[0], 4*[0], 4*[0]],\n",
    "             [[2, 3, 6, 8],\n",
    "              [1, 2, 5, 3],\n",
    "              4*[0], 4*[0], 4*[0], 4*[0], 4*[0], 4*[0]]], dtype=tf.float32)\n",
    "        num_proposals = tf.constant([3, 2], dtype=tf.int32)\n",
    "\n",
    "        # This has 1 box instead of one for each class.\n",
    "        refined_box_encodings = tf.zeros(\n",
    "            [total_num_padded_proposals, 1, 4], dtype=tf.float32)\n",
    "        class_predictions_with_background = tf.ones(\n",
    "            [total_num_padded_proposals, model.num_classes+1], dtype=tf.float32)\n",
    "        image_shape = tf.constant([batch_size, 36, 48, 3], dtype=tf.int32)\n",
    "\n",
    "        _, true_image_shapes = model.preprocess(tf.zeros(image_shape))\n",
    "        detections = model.postprocess({\n",
    "            'refined_box_encodings': refined_box_encodings,\n",
    "            'class_predictions_with_background': class_predictions_with_background,\n",
    "            'num_proposals': num_proposals,\n",
    "            'proposal_boxes': proposal_boxes,\n",
    "            'image_shape': image_shape,\n",
    "        }, true_image_shapes)\n",
    "        with self.test_session() as sess:\n",
    "          detections_out = sess.run(detections)\n",
    "          self.assertAllEqual(detections_out['detection_boxes'].shape, [2, 5, 4])\n",
    "          self.assertAllClose(detections_out['detection_scores'],\n",
    "                              [[1, 1, 1, 1, 1], [1, 1, 1, 1, 0]])\n",
    "          self.assertAllClose(detections_out['detection_classes'],\n",
    "                              [[0, 0, 0, 1, 1], [0, 0, 1, 1, 0]])\n",
    "          self.assertAllClose(detections_out['num_detections'], [5, 4])\n",
    "\n",
    "  @parameterized.parameters(\n",
    "      {'masks_are_class_agnostic': False},\n",
    "      {'masks_are_class_agnostic': True},\n",
    "  )\n",
    "  def test_predict_correct_shapes_in_inference_mode_three_stages_with_masks(\n",
    "      self, masks_are_class_agnostic):\n",
    "    batch_size = 2\n",
    "    image_size = 10\n",
    "    max_num_proposals = 8\n",
    "    initial_crop_size = 3\n",
    "    maxpool_stride = 1\n",
    "\n",
    "    input_shapes = [(batch_size, image_size, image_size, 3),\n",
    "                    (None, image_size, image_size, 3),\n",
    "                    (batch_size, None, None, 3),\n",
    "                    (None, None, None, 3)]\n",
    "    expected_num_anchors = image_size * image_size * 3 * 3\n",
    "    expected_shapes = {\n",
    "        'rpn_box_predictor_features':\n",
    "        (2, image_size, image_size, 512),\n",
    "        'rpn_features_to_crop': (2, image_size, image_size, 3),\n",
    "        'image_shape': (4,),\n",
    "        'rpn_box_encodings': (2, expected_num_anchors, 4),\n",
    "        'rpn_objectness_predictions_with_background':\n",
    "        (2, expected_num_anchors, 2),\n",
    "        'anchors': (expected_num_anchors, 4),\n",
    "        'refined_box_encodings': (2 * max_num_proposals, 2, 4),\n",
    "        'class_predictions_with_background': (2 * max_num_proposals, 2 + 1),\n",
    "        'num_proposals': (2,),\n",
    "        'proposal_boxes': (2, max_num_proposals, 4),\n",
    "        'proposal_boxes_normalized': (2, max_num_proposals, 4),\n",
    "        'box_classifier_features':\n",
    "        self._get_box_classifier_features_shape(image_size,\n",
    "                                                batch_size,\n",
    "                                                max_num_proposals,\n",
    "                                                initial_crop_size,\n",
    "                                                maxpool_stride,\n",
    "                                                3)\n",
    "    }\n",
    "\n",
    "    for input_shape in input_shapes:\n",
    "      test_graph = tf.Graph()\n",
    "      with test_graph.as_default():\n",
    "        model = self._build_model(\n",
    "            is_training=False,\n",
    "            number_of_stages=3,\n",
    "            second_stage_batch_size=2,\n",
    "            predict_masks=True,\n",
    "            masks_are_class_agnostic=masks_are_class_agnostic)\n",
    "        preprocessed_inputs = tf.placeholder(tf.float32, shape=input_shape)\n",
    "        _, true_image_shapes = model.preprocess(preprocessed_inputs)\n",
    "        result_tensor_dict = model.predict(preprocessed_inputs,\n",
    "                                           true_image_shapes)\n",
    "        init_op = tf.global_variables_initializer()\n",
    "    with self.test_session(graph=test_graph) as sess:\n",
    "        sess.run(init_op)\n",
    "        tensor_dict_out = sess.run(result_tensor_dict, feed_dict={\n",
    "            preprocessed_inputs:\n",
    "            np.zeros((batch_size, image_size, image_size, 3))})\n",
    "      self.assertEqual(\n",
    "          set(tensor_dict_out.keys()),\n",
    "          set(expected_shapes.keys()).union(\n",
    "              set([\n",
    "                  'detection_boxes', 'detection_scores', 'detection_classes',\n",
    "                  'detection_masks', 'num_detections'\n",
    "              ])))\n",
    "      for key in expected_shapes:\n",
    "        self.assertAllEqual(tensor_dict_out[key].shape, expected_shapes[key])\n",
    "      self.assertAllEqual(tensor_dict_out['detection_boxes'].shape, [2, 5, 4])\n",
    "      self.assertAllEqual(tensor_dict_out['detection_masks'].shape,\n",
    "                          [2, 5, 14, 14])\n",
    "      self.assertAllEqual(tensor_dict_out['detection_classes'].shape, [2, 5])\n",
    "      self.assertAllEqual(tensor_dict_out['detection_scores'].shape, [2, 5])\n",
    "      self.assertAllEqual(tensor_dict_out['num_detections'].shape, [2])\n",
    "\n",
    "  @parameterized.parameters(\n",
    "      {'masks_are_class_agnostic': False},\n",
    "      {'masks_are_class_agnostic': True},\n",
    "  )\n",
    "    def test_predict_gives_correct_shapes_in_train_mode_both_stages_with_masks(\n",
    "      self, masks_are_class_agnostic):\n",
    "        test_graph = tf.Graph()\n",
    "        with test_graph.as_default():\n",
    "          model = self._build_model(\n",
    "              is_training=True,\n",
    "              number_of_stages=3,\n",
    "              second_stage_batch_size=7,\n",
    "              predict_masks=True,\n",
    "              masks_are_class_agnostic=masks_are_class_agnostic)\n",
    "          batch_size = 2\n",
    "          image_size = 10\n",
    "          max_num_proposals = 7\n",
    "          initial_crop_size = 3\n",
    "          maxpool_stride = 1\n",
    "\n",
    "          image_shape = (batch_size, image_size, image_size, 3)\n",
    "          preprocessed_inputs = tf.zeros(image_shape, dtype=tf.float32)\n",
    "          groundtruth_boxes_list = [\n",
    "              tf.constant([[0, 0, .5, .5], [.5, .5, 1, 1]], dtype=tf.float32),\n",
    "              tf.constant([[0, .5, .5, 1], [.5, 0, 1, .5]], dtype=tf.float32)\n",
    "          ]\n",
    "          groundtruth_classes_list = [\n",
    "              tf.constant([[1, 0], [0, 1]], dtype=tf.float32),\n",
    "              tf.constant([[1, 0], [1, 0]], dtype=tf.float32)\n",
    "          ]\n",
    "          _, true_image_shapes = model.preprocess(tf.zeros(image_shape))\n",
    "          model.provide_groundtruth(groundtruth_boxes_list,\n",
    "                                    groundtruth_classes_list)\n",
    "\n",
    "          result_tensor_dict = model.predict(preprocessed_inputs, true_image_shapes)\n",
    "          mask_shape_1 = 1 if masks_are_class_agnostic else model._num_classes\n",
    "          expected_shapes = {\n",
    "              'rpn_box_predictor_features': (2, image_size, image_size, 512),\n",
    "              'rpn_features_to_crop': (2, image_size, image_size, 3),\n",
    "              'image_shape': (4,),\n",
    "              'refined_box_encodings': (2 * max_num_proposals, 2, 4),\n",
    "              'class_predictions_with_background': (2 * max_num_proposals, 2 + 1),\n",
    "              'num_proposals': (2,),\n",
    "              'proposal_boxes': (2, max_num_proposals, 4),\n",
    "              'proposal_boxes_normalized': (2, max_num_proposals, 4),\n",
    "              'box_classifier_features':\n",
    "                  self._get_box_classifier_features_shape(\n",
    "                      image_size, batch_size, max_num_proposals, initial_crop_size,\n",
    "                      maxpool_stride, 3),\n",
    "              'mask_predictions': (2 * max_num_proposals, mask_shape_1, 14, 14)\n",
    "          }\n",
    "\n",
    "          init_op = tf.global_variables_initializer()\n",
    "        with self.test_session(graph=test_graph) as sess:\n",
    "            sess.run(init_op)\n",
    "            tensor_dict_out = sess.run(result_tensor_dict)\n",
    "            self.assertEqual(\n",
    "                set(tensor_dict_out.keys()),\n",
    "                set(expected_shapes.keys()).union(\n",
    "                    set([\n",
    "                        'rpn_box_encodings',\n",
    "                        'rpn_objectness_predictions_with_background',\n",
    "                        'anchors',\n",
    "                    ])))\n",
    "            for key in expected_shapes:\n",
    "              self.assertAllEqual(tensor_dict_out[key].shape, expected_shapes[key])\n",
    "\n",
    "            anchors_shape_out = tensor_dict_out['anchors'].shape\n",
    "            self.assertEqual(2, len(anchors_shape_out))\n",
    "            self.assertEqual(4, anchors_shape_out[1])\n",
    "            num_anchors_out = anchors_shape_out[0]\n",
    "            self.assertAllEqual(tensor_dict_out['rpn_box_encodings'].shape,\n",
    "                                (2, num_anchors_out, 4))\n",
    "            self.assertAllEqual(\n",
    "                tensor_dict_out['rpn_objectness_predictions_with_background'].shape,\n",
    "                (2, num_anchors_out, 2))\n",
    "\n",
    "    def test_postprocess_third_stage_only_inference_mode(self):\n",
    "        num_proposals_shapes = [(2), (None)]\n",
    "        refined_box_encodings_shapes = [(16, 2, 4), (None, 2, 4)]\n",
    "        class_predictions_with_background_shapes = [(16, 3), (None, 3)]\n",
    "        proposal_boxes_shapes = [(2, 8, 4), (None, 8, 4)]\n",
    "        batch_size = 2\n",
    "        image_shape = np.array((2, 36, 48, 3), dtype=np.int32)\n",
    "        for (num_proposals_shape, refined_box_encoding_shape,\n",
    "             class_predictions_with_background_shape,\n",
    "             proposal_boxes_shape) in zip(num_proposals_shapes,\n",
    "                                          refined_box_encodings_shapes,\n",
    "                                          class_predictions_with_background_shapes,\n",
    "                                          proposal_boxes_shapes):\n",
    "          tf_graph = tf.Graph()\n",
    "          with tf_graph.as_default():\n",
    "            model = self._build_model(\n",
    "                is_training=False, number_of_stages=3,\n",
    "                second_stage_batch_size=6, predict_masks=True)\n",
    "            total_num_padded_proposals = batch_size * model.max_num_proposals\n",
    "            proposal_boxes = np.array(\n",
    "                [[[1, 1, 2, 3],\n",
    "                  [0, 0, 1, 1],\n",
    "                  [.5, .5, .6, .6],\n",
    "                  4*[0], 4*[0], 4*[0], 4*[0], 4*[0]],\n",
    "                 [[2, 3, 6, 8],\n",
    "                  [1, 2, 5, 3],\n",
    "                  4*[0], 4*[0], 4*[0], 4*[0], 4*[0], 4*[0]]])\n",
    "            num_proposals = np.array([3, 2], dtype=np.int32)\n",
    "            refined_box_encodings = np.zeros(\n",
    "                [total_num_padded_proposals, model.num_classes, 4])\n",
    "            class_predictions_with_background = np.ones(\n",
    "                [total_num_padded_proposals, model.num_classes+1])\n",
    "\n",
    "            num_proposals_placeholder = tf.placeholder(tf.int32,\n",
    "                                                       shape=num_proposals_shape)\n",
    "            refined_box_encodings_placeholder = tf.placeholder(\n",
    "                tf.float32, shape=refined_box_encoding_shape)\n",
    "            class_predictions_with_background_placeholder = tf.placeholder(\n",
    "                tf.float32, shape=class_predictions_with_background_shape)\n",
    "            proposal_boxes_placeholder = tf.placeholder(\n",
    "                tf.float32, shape=proposal_boxes_shape)\n",
    "            image_shape_placeholder = tf.placeholder(tf.int32, shape=(4))\n",
    "            _, true_image_shapes = model.preprocess(\n",
    "                tf.zeros(image_shape_placeholder))\n",
    "            detections = model.postprocess({\n",
    "                'refined_box_encodings': refined_box_encodings_placeholder,\n",
    "                'class_predictions_with_background':\n",
    "                class_predictions_with_background_placeholder,\n",
    "                'num_proposals': num_proposals_placeholder,\n",
    "                'proposal_boxes': proposal_boxes_placeholder,\n",
    "                'image_shape': image_shape_placeholder,\n",
    "                'detection_boxes': tf.zeros([2, 5, 4]),\n",
    "                'detection_masks': tf.zeros([2, 5, 14, 14]),\n",
    "                'detection_scores': tf.zeros([2, 5]),\n",
    "                'detection_classes': tf.zeros([2, 5]),\n",
    "                'num_detections': tf.zeros([2]),\n",
    "            }, true_image_shapes)\n",
    "        with self.test_session(graph=tf_graph) as sess:\n",
    "            detections_out = sess.run(\n",
    "                detections,\n",
    "                feed_dict={\n",
    "                    refined_box_encodings_placeholder: refined_box_encodings,\n",
    "                    class_predictions_with_background_placeholder:\n",
    "                    class_predictions_with_background,\n",
    "                    num_proposals_placeholder: num_proposals,\n",
    "                    proposal_boxes_placeholder: proposal_boxes,\n",
    "                    image_shape_placeholder: image_shape\n",
    "                })\n",
    "          self.assertAllEqual(detections_out['detection_boxes'].shape, [2, 5, 4])\n",
    "          self.assertAllEqual(detections_out['detection_masks'].shape,\n",
    "                              [2, 5, 14, 14])\n",
    "          self.assertAllClose(detections_out['detection_scores'].shape, [2, 5])\n",
    "          self.assertAllClose(detections_out['detection_classes'].shape, [2, 5])\n",
    "          self.assertAllClose(detections_out['num_detections'].shape, [2])\n",
    "          self.assertTrue(np.amax(detections_out['detection_masks'] <= 1.0))\n",
    "          self.assertTrue(np.amin(detections_out['detection_masks'] >= 0.0))\n",
    "\n",
    "    def _get_box_classifier_features_shape(self,\n",
    "                                         image_size,\n",
    "                                         batch_size,\n",
    "                                         max_num_proposals,\n",
    "                                         initial_crop_size,\n",
    "                                         maxpool_stride,\n",
    "                                         num_features):\n",
    "        return (batch_size * max_num_proposals,\n",
    "                initial_crop_size/maxpool_stride,\n",
    "                initial_crop_size/maxpool_stride,\n",
    "                num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
