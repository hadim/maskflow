{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "- Compute average precision and average recall on the test dataset of a given model.\n",
    "- The evaluation metrics are the ones defined in the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "import sys; sys.path.append(\"../\")\n",
    "import maskflow\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/C_elegans\")\n",
    "data_dir = root_dir / \"Data\"\n",
    "model_dir = root_dir / \"Models\"\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Import the configuration associated with this dataset and network.\n",
    "config = maskflow.config.load_config(root_dir / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-10 23:47:58,230:INFO:maskrcnn_benchmark.utils.checkpoint: Loading checkpoint from /home/hadim/.data/Neural_Network/Maskflow/C_elegans/Models/2018.11.10-23:30:55/model_0000250.pth\n",
      "2018-11-10 23:47:58,583:WARNING:maskrcnn_benchmark.data.build: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2018-11-10 23:47:58,653:INFO:maskrcnn_benchmark.inference: Start evaluation on 20 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/hadim/conda/envs/nn/lib/python3.6/site-packages/torch/nn/functional.py:2096: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "2it [00:08,  5.64s/it]\n",
      "2018-11-10 23:48:08,401:INFO:maskrcnn_benchmark.inference: Total inference time: 0:00:09.743486 (0.48717432022094725 s / img per device, on 1 devices)\n",
      "2018-11-10 23:48:08,402:INFO:maskrcnn_benchmark.inference: Preparing results for COCO format\n",
      "2018-11-10 23:48:08,404:INFO:maskrcnn_benchmark.inference: Preparing bbox results\n",
      "2018-11-10 23:48:08,419:INFO:maskrcnn_benchmark.inference: Preparing segm results\n",
      "20it [00:00, 85.18it/s]\n",
      "2018-11-10 23:48:08,665:INFO:maskrcnn_benchmark.inference: Evaluating predictions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.32s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.622\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.880\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.693\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.634\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.665\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.057\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.564\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.689\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.641\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.770\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-10 23:48:09,512:INFO:maskrcnn_benchmark.inference: OrderedDict([('bbox', OrderedDict([('AP', 0.6222989867726723), ('AP50', 0.8799681542576778), ('AP75', 0.6933596511797944), ('APs', 0.6344390275095129), ('APm', 0.6649455794430983), ('APl', -1.0)])), ('segm', OrderedDict([('AP', 0.5057224507325584), ('AP50', 0.8040537209755729), ('AP75', 0.5941074543219045), ('APs', 0.46026071657222634), ('APm', 0.5761194578043566), ('APl', -1.0)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE (t=0.36s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.506\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.804\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.594\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.460\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.576\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.480\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.592\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.545\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.660\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    }
   ],
   "source": [
    "# Select the model\n",
    "model_name = '2018.11.10-23:30:55'\n",
    "model_path = model_dir / model_name\n",
    "\n",
    "# Set some configurations\n",
    "config['MODEL']['DEVICE'] = \"cuda\"\n",
    "config['DATALOADER']['NUM_WORKERS'] = 16\n",
    "config['TEST']['IMS_PER_BATCH'] = 16\n",
    "    \n",
    "# Run the evaluation\n",
    "# (it will create a file called evauation.json in `model_path`)\n",
    "results = maskflow.inference.run_evaluation(config, model_path, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Microtubule, `2018.11.10-16:39:38`:\n",
    "\n",
    "| Step | mAP | mAR | AP@0.50 | AP@0.75\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 750 | 0.33 | 0.02 | 0.62 | 0.32 |\n",
    "| 1000 | 0.33 | 0.02 | 0.61 | 0.31 |\n",
    "| 1500 | 0.34 | 0.02 | 0.61 | 0.33 |\n",
    "| 2500 | 0.36 | 0.019 | 0.65 | 0.36 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
