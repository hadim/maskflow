{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "- Compute average precision and average recall on the test dataset of a given model.\n",
    "- The evaluation metrics are the ones defined in the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "import sys; sys.path.append(\"../\")\n",
    "import maskflow\n",
    "\n",
    "root_dir = Path(\"/home/hadim/.data/Neural_Network/Maskflow/Microtubule\")\n",
    "data_dir = root_dir / \"Data Small\"\n",
    "model_dir = root_dir / \"Models\"\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Import the configuration associated with this dataset and network.\n",
    "config = maskflow.config.load_config(root_dir / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-10 15:41:34,815:INFO:maskrcnn_benchmark.utils.checkpoint: Loading checkpoint from /home/hadim/.data/Neural_Network/Maskflow/Microtubule/Models/2018.11.10-15:38:43/model_0000200.pth\n",
      "2018-11-10 15:41:35,030:WARNING:maskrcnn_benchmark.data.build: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n",
      "2018-11-10 15:41:35,040:INFO:maskrcnn_benchmark.inference: Start evaluation on 4 images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.58s/it]\n",
      "2018-11-10 15:41:38,036:INFO:maskrcnn_benchmark.inference: Total inference time: 0:00:02.995769 (0.7489421367645264 s / img per device, on 1 devices)\n",
      "2018-11-10 15:41:38,037:INFO:maskrcnn_benchmark.inference: Preparing results for COCO format\n",
      "2018-11-10 15:41:38,037:INFO:maskrcnn_benchmark.inference: Preparing bbox results\n",
      "2018-11-10 15:41:38,040:INFO:maskrcnn_benchmark.inference: Preparing segm results\n",
      "4it [00:00, 1922.23it/s]\n",
      "2018-11-10 15:41:38,044:INFO:maskrcnn_benchmark.inference: Evaluating predictions\n",
      "2018-11-10 15:41:38,076:INFO:maskrcnn_benchmark.inference: OrderedDict([('bbox', OrderedDict([('AP', 0.30973597359735977), ('AP50', 0.5627062706270627), ('AP75', 0.31683168316831684), ('APs', 0.30973597359735977), ('APm', -1.0), ('APl', -1.0)])), ('segm', OrderedDict([('AP', 0.2419141914191419), ('AP50', 0.5825082508250825), ('AP75', 0.1287128712871287), ('APs', 0.2419141914191419), ('APm', -1.0), ('APl', -1.0)]))])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.563\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.310\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.362\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.00s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.00s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.583\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.175\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.263\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"
     ]
    }
   ],
   "source": [
    "# Select the model\n",
    "model_name = '2018.11.10-15:38:43'\n",
    "model_path = model_dir / model_name\n",
    "\n",
    "# Set some configurations\n",
    "config['MODEL']['DEVICE'] = \"cpu\"\n",
    "config['DATALOADER']['NUM_WORKERS'] = 16\n",
    "config['TEST']['IMS_PER_BATCH'] = 8\n",
    "    \n",
    "# Run the evaluation\n",
    "# (it will create a file called evauation.json in `model_path`)\n",
    "results = maskflow.inference.run_evaluation(config, model_path, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Microtubule, `2018.11.10-16:39:38`:\n",
    "\n",
    "| Step | mAP | mAR | AP@0.50 | AP@0.75\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 750 | 0.33 | 0.02 | 0.62 | 0.32 |\n",
    "| 1000 | 0.33 | 0.02 | 0.61 | 0.31 |\n",
    "| 1500 | 0.34 | 0.02 | 0.61 | 0.33 |\n",
    "| 2500 | 0.36 | 0.019 | 0.65 | 0.36 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn]",
   "language": "python",
   "name": "conda-env-nn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
